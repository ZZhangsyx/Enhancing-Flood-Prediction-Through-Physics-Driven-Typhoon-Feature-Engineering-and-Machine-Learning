{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf78e2-fe17-42c0-929a-16f2cda5e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# Create directories for saving results\n",
    "os.makedirs('models_v2/baseline', exist_ok=True)\n",
    "os.makedirs('models_v2/with_typhoon', exist_ok=True)\n",
    "os.makedirs('models_v2/with_typhoon_enhanced', exist_ok=True)\n",
    "os.makedirs('predictions_v2', exist_ok=True)\n",
    "os.makedirs('results_v2', exist_ok=True)\n",
    "\n",
    "# ================== Step 1: Typhoon Feature Engineering ==================\n",
    "\n",
    "def create_typhoon_features(df):\n",
    "    \"\"\"\n",
    "    Create enhanced typhoon features - improved version\n",
    "    \n",
    "    Improvements:\n",
    "    1. Use non-linear transformation for distance feature (sigmoid function)\n",
    "    2. Create comprehensive impact index with physical meaning\n",
    "    3. Add relative position features (typhoon position relative to Boluo Station)\n",
    "    4. Standardize air pressure feature\n",
    "    5. Create intensity accumulation features (consider impact intensity not just presence)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Typhoon active flag (basic binary feature)\n",
    "    df['typhoon_active'] = (df['typhoon_grade'] != 0).astype(int)\n",
    "    \n",
    "    # 2. Numerical encoding of typhoon intensity grade\n",
    "    def map_intensity(val):\n",
    "        if pd.isna(val) or val == 0 or val == '0':\n",
    "            return 0\n",
    "        \n",
    "        val_str = str(val).upper()\n",
    "        \n",
    "        if 'TD' in val_str or 'TROPICAL DEPRESSION' in val_str:\n",
    "            return 1\n",
    "        elif 'TS' in val_str or ('TROPICAL STORM' in val_str and 'SEVERE' not in val_str):\n",
    "            return 2\n",
    "        elif 'STS' in val_str or 'SEVERE TROPICAL STORM' in val_str:\n",
    "            return 3\n",
    "        elif 'STY' in val_str or 'SUPER TYPHOON' in val_str:\n",
    "            return 6\n",
    "        elif 'TY' in val_str or ('TYPHOON' in val_str and 'SUPER' not in val_str and 'SEVERE' not in val_str):\n",
    "            return 4\n",
    "        elif 'SEVERE TYPHOON' in val_str:\n",
    "            return 5\n",
    "        else:\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return 0\n",
    "    \n",
    "    df['typhoon_intensity_encoded'] = df['typhoon_intensity'].apply(map_intensity)\n",
    "    \n",
    "    # 3. 【Improved】Typhoon distance impact weight (non-linear transformation using sigmoid function)\n",
    "    # Sigmoid function converts distance to 0-1 impact weight\n",
    "    # Impact weight is 0.5 at 250km, higher weight for closer distance\n",
    "    df['typhoon_distance_impact'] = df.apply(\n",
    "        lambda row: 1 / (1 + np.exp((row['distance_to_boluo'] - 250) / 50)) if row['distance_to_boluo'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 4. 【Improved】Comprehensive typhoon impact index (non-linear combination of wind speed, grade and distance)\n",
    "    df['typhoon_comprehensive_impact'] = df['wind_speed'] * df['typhoon_grade'] * df['typhoon_distance_impact']\n",
    "    \n",
    "    # 5. 【Improved】Typhoon wind force grade (based on Beaufort scale)\n",
    "    def classify_wind(speed):\n",
    "        if speed == 0:\n",
    "            return 0\n",
    "        elif speed < 17.2:\n",
    "            return 1  # Tropical Depression\n",
    "        elif speed < 24.5:\n",
    "            return 2  # Tropical Storm\n",
    "        elif speed < 32.7:\n",
    "            return 3  # Severe Tropical Storm\n",
    "        elif speed < 41.5:\n",
    "            return 4  # Typhoon\n",
    "        elif speed < 51.0:\n",
    "            return 5  # Severe Typhoon\n",
    "        else:\n",
    "            return 6  # Super Typhoon\n",
    "    \n",
    "    df['wind_force_grade'] = df['wind_speed'].apply(classify_wind)\n",
    "    \n",
    "    # 6. 【Improved】Air pressure intensity (standardized deviation from standard atmospheric pressure)\n",
    "    # Lower pressure means stronger typhoon, standardized by dividing by 50\n",
    "    df['air_pressure_intensity'] = df.apply(\n",
    "        lambda row: (1013.25 - row['air_pressure']) / 50 if row['air_pressure'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 7. Typhoon duration feature\n",
    "    df['typhoon_duration_days'] = df['days_since_typhoon_start']\n",
    "    \n",
    "    # 8. Typhoon occurrence accumulation (sliding window - count typhoon presence)\n",
    "    df['typhoon_accumulated_3d'] = df['typhoon_active'].rolling(window=3, min_periods=1).sum()\n",
    "    df['typhoon_accumulated_7d'] = df['typhoon_active'].rolling(window=7, min_periods=1).sum()\n",
    "    \n",
    "    # 9. 【New】Typhoon impact intensity accumulation (sliding window - average impact intensity)\n",
    "    # This feature considers both presence and actual impact intensity of typhoons\n",
    "    df['typhoon_intensity_accumulated_3d'] = df['typhoon_comprehensive_impact'].rolling(window=3, min_periods=1).mean()\n",
    "    df['typhoon_intensity_accumulated_7d'] = df['typhoon_comprehensive_impact'].rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    # 10. Typhoon movement features\n",
    "    df['typhoon_longitude_change'] = df['typhoon_longitude'].diff().fillna(0)\n",
    "    df['typhoon_latitude_change'] = df['typhoon_latitude'].diff().fillna(0)\n",
    "    df['typhoon_movement_speed'] = np.sqrt(df['typhoon_longitude_change']**2 + df['typhoon_latitude_change']**2)\n",
    "    \n",
    "    # 11. 【New】Typhoon relative position features (deviation from Boluo Station)\n",
    "    # Captures directional information of typhoon relative to Boluo\n",
    "    boluo_lon = 114.2967\n",
    "    boluo_lat = 23.15881\n",
    "    df['typhoon_relative_longitude'] = df['typhoon_longitude'] - boluo_lon\n",
    "    df['typhoon_relative_latitude'] = df['typhoon_latitude'] - boluo_lat\n",
    "    \n",
    "    # 12. 【New】Season-typhoon interaction feature\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['is_typhoon_season'] = df['month'].isin([6, 7, 8, 9, 10]).astype(int)\n",
    "    df['typhoon_season_intensity'] = df['typhoon_comprehensive_impact'] * df['is_typhoon_season']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ================== Step 2: Create Lagged Features ==================\n",
    "\n",
    "def create_lagged_features(df, target_column, lag_days=7, feature_type='baseline'):\n",
    "    \"\"\"\n",
    "    Create lagged features for the past lag_days to predict target column, named in (T-1) format\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Define typhoon-related columns\n",
    "    typhoon_base_cols = ['days_since_typhoon_start', 'typhoon_longitude', 'typhoon_latitude', \n",
    "                         'typhoon_grade', 'typhoon_intensity', 'wind_speed', 'air_pressure', 'distance_to_boluo']\n",
    "\n",
    "    delete_cols = ['boluo_discharge','baipenzhu_outflow', 'boluo', 'boluo_T' , 'boluo_p', 'boluo_E', 'andun', \n",
    "                  'dabeibu', 'pingshan']\n",
    "    delete_cols2 = ['boluo_discharge','baipenzhu_outflow', 'boluo', 'boluo_T', 'boluo_p',  'boluo_E']\n",
    "        \n",
    "    # 【Modified】Update enhanced feature list to match create_typhoon_features()\n",
    "    typhoon_enhanced_cols = [\n",
    "        'typhoon_active',                # Typhoon active flag\n",
    "        'typhoon_intensity_encoded',     # Intensity numerical encoding\n",
    "        'typhoon_distance_impact',       # Improved: sigmoid distance impact (formerly 'typhoon_distance_reciprocal')\n",
    "        'typhoon_comprehensive_impact',  # Improved: comprehensive impact index (formerly 'typhoon_impact_index')\n",
    "        'wind_force_grade',              # Wind force classification (formerly 'wind_speed_grade')\n",
    "        'air_pressure_intensity',        # Improved: standardized air pressure (formerly 'air_pressure_diff')\n",
    "        'typhoon_duration_days',         # New: duration days\n",
    "        'typhoon_accumulated_3d',        # Active accumulation\n",
    "        'typhoon_accumulated_7d',        # Active accumulation\n",
    "        'typhoon_intensity_accumulated_3d',  # New: intensity accumulation\n",
    "        'typhoon_intensity_accumulated_7d',  # New: intensity accumulation\n",
    "        'typhoon_longitude_change',      # Movement feature\n",
    "        'typhoon_latitude_change',       # Movement feature\n",
    "        'typhoon_movement_speed',        # Movement feature\n",
    "        'typhoon_relative_longitude',    # New: relative position\n",
    "        'typhoon_relative_latitude',     # New: relative position\n",
    "        'month',                         # Season feature\n",
    "        'is_typhoon_season',             # New: typhoon season flag\n",
    "        'typhoon_season_intensity'       # New: season interaction (formerly 'typhoon_season_interaction')\n",
    "    ]\n",
    "    \n",
    "    # Select columns based on feature type\n",
    "    exclude_cols = ['date', target_column]\n",
    "    \n",
    "    if feature_type == 'baseline':\n",
    "        # Baseline model: exclude all typhoon-related features\n",
    "        exclude_cols.extend(typhoon_base_cols)\n",
    "        exclude_cols.extend(typhoon_enhanced_cols)\n",
    "        exclude_cols.extend(delete_cols)\n",
    "    elif feature_type == 'with_typhoon':\n",
    "        # Include original typhoon features, exclude enhanced features and raw intensity column (contains strings)\n",
    "        exclude_cols.extend(typhoon_enhanced_cols)\n",
    "        exclude_cols.append('typhoon_intensity')  # Exclude raw intensity column, use encoded version\n",
    "        exclude_cols.extend(delete_cols2)\n",
    "    elif feature_type == 'with_typhoon_enhanced':\n",
    "        # Include all features, exclude raw typhoon intensity column\n",
    "        exclude_cols.append('typhoon_intensity')  # Exclude raw intensity column\n",
    "    \n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    for i in range(len(df) - lag_days):\n",
    "        feature = df[feature_cols].iloc[i:i + lag_days].values.flatten()\n",
    "        label = df[target_column].iloc[i + lag_days]\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Generate feature column names (T-1, T-2, ..., T-7 format)\n",
    "    feature_columns = []\n",
    "    for day in range(1, lag_days + 1):\n",
    "        for col in feature_cols:\n",
    "            feature_columns.append(f'{col}(T-{day})')\n",
    "    \n",
    "    features = pd.DataFrame(features, columns=feature_columns)\n",
    "    labels = pd.Series(labels, name=target_column)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def prepare_data(data_file, lag_days=7):\n",
    "    \"\"\"\n",
    "    Prepare three datasets: baseline, with original typhoon features, with enhanced typhoon features\n",
    "    \"\"\"\n",
    "    # Read data\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    # Data preprocessing: fill values less than 0 with 0\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_columns] = df[numeric_columns].applymap(lambda x: 0 if x < 0 else x)\n",
    "    \n",
    "    # Create enhanced typhoon features\n",
    "    print(\"Creating enhanced typhoon features...\")\n",
    "    df_enhanced = create_typhoon_features(df)\n",
    "    \n",
    "    # Create three datasets\n",
    "    print(\"Creating baseline dataset (without typhoon features)...\")\n",
    "    features_baseline, labels_baseline = create_lagged_features(\n",
    "        df_enhanced, 'boluo_discharge', lag_days=lag_days, feature_type='baseline'\n",
    "    )\n",
    "    combined_baseline = pd.concat([features_baseline, labels_baseline], axis=1)\n",
    "    combined_baseline['date'] = df_enhanced['date'][lag_days:].values\n",
    "    \n",
    "    print(\"Creating dataset with original typhoon features...\")\n",
    "    features_typhoon, labels_typhoon = create_lagged_features(\n",
    "        df_enhanced, 'boluo_discharge', lag_days=lag_days, feature_type='with_typhoon'\n",
    "    )\n",
    "    combined_typhoon = pd.concat([features_typhoon, labels_typhoon], axis=1)\n",
    "    combined_typhoon['date'] = df_enhanced['date'][lag_days:].values\n",
    "    \n",
    "    print(\"Creating dataset with enhanced typhoon features...\")\n",
    "    features_enhanced, labels_enhanced = create_lagged_features(\n",
    "        df_enhanced, 'boluo_discharge', lag_days=lag_days, feature_type='with_typhoon_enhanced'\n",
    "    )\n",
    "    combined_enhanced = pd.concat([features_enhanced, labels_enhanced], axis=1)\n",
    "    combined_enhanced['date'] = df_enhanced['date'][lag_days:].values\n",
    "    \n",
    "    return combined_baseline, combined_typhoon, combined_enhanced\n",
    "\n",
    "def split_data(combined_data, train_start='1985-01-01', train_end='2004-12-31',\n",
    "               test_start='2005-01-01', test_end='2013-12-31'):\n",
    "    \"\"\"\n",
    "    Split into training and testing sets\n",
    "    \"\"\"\n",
    "    combined_data['date'] = pd.to_datetime(combined_data['date'])\n",
    "    \n",
    "    train_data = combined_data[\n",
    "        (combined_data['date'] >= train_start) & \n",
    "        (combined_data['date'] <= train_end)\n",
    "    ].copy()\n",
    "    test_data = combined_data[\n",
    "        (combined_data['date'] >= test_start) & \n",
    "        (combined_data['date'] <= test_end)\n",
    "    ].copy()\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# ================== Step 3: Flood Event Identification ==================\n",
    "\n",
    "def identify_flood_events(y_data, dates, threshold_percentile=90):\n",
    "    \"\"\"\n",
    "    Identify flood events\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(y_data, threshold_percentile)\n",
    "    flood_indices = np.where(y_data >= threshold)[0]\n",
    "    \n",
    "    print(f\"Flood threshold ({threshold_percentile}th percentile): {threshold:.2f} m³/s\")\n",
    "    print(f\"Flood event days: {len(flood_indices)} ({len(flood_indices)/len(y_data)*100:.2f}%)\")\n",
    "    \n",
    "    return flood_indices, threshold\n",
    "\n",
    "# ================== Step 4: Evaluation Metrics ==================\n",
    "\n",
    "def nse(y_true, y_pred):\n",
    "    \"\"\"Nash-Sutcliffe Efficiency (NSE)\"\"\"\n",
    "    return 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - np.mean(y_true))**2))\n",
    "\n",
    "def kge(y_true, y_pred):\n",
    "    \"\"\"Kling-Gupta Efficiency (KGE)\"\"\"\n",
    "    mean_obs = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    std_obs = np.std(y_true)\n",
    "    std_pred = np.std(y_pred)\n",
    "    r = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "    \n",
    "    return 1 - np.sqrt((r - 1)**2 + (std_pred/std_obs - 1)**2 + (mean_pred/mean_obs - 1)**2)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, flood_indices=None):\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics\n",
    "    \"\"\"\n",
    "    # Overall evaluation metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    nse_val = nse(y_true, y_pred)\n",
    "    kge_val = kge(y_true, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'NSE': nse_val,\n",
    "        'KGE': kge_val\n",
    "    }\n",
    "    \n",
    "    # Calculate flood period metrics if flood indices are provided\n",
    "    if flood_indices is not None and len(flood_indices) > 0:\n",
    "        y_true_flood = y_true.iloc[flood_indices]\n",
    "        y_pred_flood = y_pred[flood_indices]\n",
    "        \n",
    "        rmse_flood = np.sqrt(mean_squared_error(y_true_flood, y_pred_flood))\n",
    "        mae_flood = mean_absolute_error(y_true_flood, y_pred_flood)\n",
    "        nse_flood = nse(y_true_flood, y_pred_flood)\n",
    "        kge_flood = kge(y_true_flood, y_pred_flood)\n",
    "        \n",
    "        metrics['RMSE_flood'] = rmse_flood\n",
    "        metrics['MAE_flood'] = mae_flood\n",
    "        metrics['NSE_flood'] = nse_flood\n",
    "        metrics['KGE_flood'] = kge_flood\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ================== Step 5: Model Definition ==================\n",
    "\n",
    "def get_models_and_params():\n",
    "    \"\"\"Return 4 core models and corresponding parameter grids\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # Linear Regression\n",
    "    lr = LinearRegression()\n",
    "    lr_params = {\n",
    "        'fit_intercept': [True, False]\n",
    "    }\n",
    "    \n",
    "    # Artificial Neural Network\n",
    "    ann = MLPRegressor(max_iter=2000, random_state=42, early_stopping=True)\n",
    "    ann_params = {\n",
    "        'hidden_layer_sizes': [(64,), (128,), (64, 32)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "    \n",
    "    # Random Forest\n",
    "    rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    rf_params = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 15, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'LR': {'model': lr, 'params': lr_params, 'cv': tscv},\n",
    "        'ANN': {'model': ann, 'params': ann_params, 'cv': tscv},\n",
    "        'RF': {'model': rf, 'params': rf_params, 'cv': tscv},\n",
    "        'XGB': {'model': xgb, 'params': xgb_params, 'cv': tscv}\n",
    "    }\n",
    "\n",
    "# ================== Step 6: Training and Evaluation ==================\n",
    "\n",
    "def train_and_compare(X_train, y_train, X_test, y_test, dates_test, \n",
    "                     scenario_name, flood_indices):\n",
    "    \"\"\"\n",
    "    Train and evaluate all models\n",
    "    \"\"\"\n",
    "    models_info = get_models_and_params()\n",
    "    results = {}\n",
    "    \n",
    "    for name, info in models_info.items():\n",
    "        # Check if model already exists\n",
    "        model_path = f'models_v2/{scenario_name}/{name}_best_model.pkl'\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"\\n{name} model already exists, skipping training and loading directly...\")\n",
    "            best_estimator = joblib.load(model_path)\n",
    "            \n",
    "            # Prediction\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            \n",
    "            # Evaluation\n",
    "            metrics = evaluate_model(y_test, y_pred, flood_indices)\n",
    "            \n",
    "            print(f\"{name} - NSE: {metrics['NSE']:.4f}, RMSE: {metrics['RMSE']:.2f}\")\n",
    "            \n",
    "            # Save prediction results\n",
    "            predictions_df = pd.DataFrame({\n",
    "                'date': dates_test.values,\n",
    "                'observed': y_test.values,\n",
    "                'predicted': y_pred\n",
    "            })\n",
    "            predictions_df.to_csv(f'predictions_v2/{scenario_name}_{name}_predictions.csv', index=False)\n",
    "            \n",
    "            results[name] = {\n",
    "                'best_params': 'loaded_from_file',\n",
    "                'metrics': metrics\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\nTraining {name} model ({scenario_name})...\")\n",
    "            \n",
    "            # Grid search for hyperparameter tuning\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=info['model'],\n",
    "                param_grid=info['params'],\n",
    "                cv=info['cv'],\n",
    "                scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Train model\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model\n",
    "            best_estimator = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            \n",
    "            # Prediction\n",
    "            y_pred = best_estimator.predict(X_test)\n",
    "            \n",
    "            # Evaluation\n",
    "            metrics = evaluate_model(y_test, y_pred, flood_indices)\n",
    "            \n",
    "            print(f\"{name} completed - NSE: {metrics['NSE']:.4f}, RMSE: {metrics['RMSE']:.2f}\")\n",
    "            \n",
    "            # Save model\n",
    "            joblib.dump(best_estimator, model_path)\n",
    "            \n",
    "            # Save prediction results\n",
    "            predictions_df = pd.DataFrame({\n",
    "                'date': dates_test.values,\n",
    "                'observed': y_test.values,\n",
    "                'predicted': y_pred\n",
    "            })\n",
    "            predictions_df.to_csv(f'predictions_v2/{scenario_name}_{name}_predictions.csv', index=False)\n",
    "            \n",
    "            # Save results\n",
    "            results[name] = {\n",
    "                'best_params': best_params,\n",
    "                'metrics': metrics\n",
    "            }\n",
    "    \n",
    "    # Save scenario results\n",
    "    with open(f'results_v2/{scenario_name}_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================== Step 7: Results Comparison Tables ==================\n",
    "\n",
    "def print_comparison_tables(results_baseline, results_typhoon, results_enhanced):\n",
    "    \"\"\"\n",
    "    Print comparison tables for 4 metrics\n",
    "    \"\"\"\n",
    "    models = ['LR', 'ANN', 'RF', 'XGB']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"Experimental Results Comparison\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Table 1: Overall NSE comparison\n",
    "    print(\"\\n【Table 1】Overall NSE Metric Comparison\")\n",
    "    print(\"-\"*100)\n",
    "    print(f\"{'Model':<10} {'Baseline':>15} {'Original Typhoon':>18} {'Enhanced Typhoon':>18} {'Original Imp%':>12} {'Enhanced Imp%':>12}\")\n",
    "    print(\"-\"*100)\n",
    "    for model in models:\n",
    "        baseline = results_baseline[model]['metrics']['NSE']\n",
    "        typhoon = results_typhoon[model]['metrics']['NSE']\n",
    "        enhanced = results_enhanced[model]['metrics']['NSE']\n",
    "        imp_typhoon = ((typhoon - baseline) / abs(baseline + 1e-10)) * 100\n",
    "        imp_enhanced = ((enhanced - baseline) / abs(baseline + 1e-10)) * 100\n",
    "        print(f\"{model:<10} {baseline:>15.4f} {typhoon:>18.4f} {enhanced:>18.4f} {imp_typhoon:>11.2f}% {imp_enhanced:>11.2f}%\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # Table 2: Overall RMSE comparison\n",
    "    print(\"\\n【Table 2】Overall RMSE Metric Comparison\")\n",
    "    print(\"-\"*100)\n",
    "    print(f\"{'Model':<10} {'Baseline':>15} {'Original Typhoon':>18} {'Enhanced Typhoon':>18} {'Original Red%':>12} {'Enhanced Red%':>12}\")\n",
    "    print(\"-\"*100)\n",
    "    for model in models:\n",
    "        baseline = results_baseline[model]['metrics']['RMSE']\n",
    "        typhoon = results_typhoon[model]['metrics']['RMSE']\n",
    "        enhanced = results_enhanced[model]['metrics']['RMSE']\n",
    "        imp_typhoon = ((baseline - typhoon) / abs(baseline + 1e-10)) * 100\n",
    "        imp_enhanced = ((baseline - enhanced) / abs(baseline + 1e-10)) * 100\n",
    "        print(f\"{model:<10} {baseline:>15.2f} {typhoon:>18.2f} {enhanced:>18.2f} {imp_typhoon:>11.2f}% {imp_enhanced:>11.2f}%\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # Table 3: Flood period NSE comparison\n",
    "    print(\"\\n【Table 3】Flood Period NSE Metric Comparison\")\n",
    "    print(\"-\"*100)\n",
    "    print(f\"{'Model':<10} {'Baseline':>15} {'Original Typhoon':>18} {'Enhanced Typhoon':>18} {'Original Imp%':>12} {'Enhanced Imp%':>12}\")\n",
    "    print(\"-\"*100)\n",
    "    for model in models:\n",
    "        baseline = results_baseline[model]['metrics'].get('NSE_flood', 0)\n",
    "        typhoon = results_typhoon[model]['metrics'].get('NSE_flood', 0)\n",
    "        enhanced = results_enhanced[model]['metrics'].get('NSE_flood', 0)\n",
    "        imp_typhoon = ((typhoon - baseline) / abs(baseline + 1e-10)) * 100\n",
    "        imp_enhanced = ((enhanced - baseline) / abs(baseline + 1e-10)) * 100\n",
    "        print(f\"{model:<10} {baseline:>15.4f} {typhoon:>18.4f} {enhanced:>18.4f} {imp_typhoon:>11.2f}% {imp_enhanced:>11.2f}%\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # Table 4: Flood period RMSE comparison\n",
    "    print(\"\\n【Table 4】Flood Period RMSE Metric Comparison\")\n",
    "    print(\"-\"*100)\n",
    "    print(f\"{'Model':<10} {'Baseline':>15} {'Original Typhoon':>18} {'Enhanced Typhoon':>18} {'Original Red%':>12} {'Enhanced Red%':>12}\")\n",
    "    print(\"-\"*100)\n",
    "    for model in models:\n",
    "        baseline = results_baseline[model]['metrics'].get('RMSE_flood', 0)\n",
    "        typhoon = results_typhoon[model]['metrics'].get('RMSE_flood', 0)\n",
    "        enhanced = results_enhanced[model]['metrics'].get('RMSE_flood', 0)\n",
    "        imp_typhoon = ((baseline - typhoon) / abs(baseline + 1e-10)) * 100\n",
    "        imp_enhanced = ((baseline - enhanced) / abs(baseline + 1e-10)) * 100\n",
    "        print(f\"{model:<10} {baseline:>15.2f} {typhoon:>18.2f} {enhanced:>18.2f} {imp_typhoon:>11.2f}% {imp_enhanced:>11.2f}%\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # Save tables to CSV\n",
    "    save_tables_to_csv(results_baseline, results_typhoon, results_enhanced, models)\n",
    "\n",
    "def save_tables_to_csv(results_baseline, results_typhoon, results_enhanced, models):\n",
    "    \"\"\"\n",
    "    Save comparison tables to CSV files\n",
    "    \"\"\"\n",
    "    # Overall metrics table\n",
    "    overall_data = []\n",
    "    for model in models:\n",
    "        row = {\n",
    "            'Model': model,\n",
    "            'Baseline_NSE': results_baseline[model]['metrics']['NSE'],\n",
    "            'Baseline_RMSE': results_baseline[model]['metrics']['RMSE'],\n",
    "            'Baseline_MAE': results_baseline[model]['metrics']['MAE'],\n",
    "            'Baseline_KGE': results_baseline[model]['metrics']['KGE'],\n",
    "            'Original_Typhoon_NSE': results_typhoon[model]['metrics']['NSE'],\n",
    "            'Original_Typhoon_RMSE': results_typhoon[model]['metrics']['RMSE'],\n",
    "            'Original_Typhoon_MAE': results_typhoon[model]['metrics']['MAE'],\n",
    "            'Original_Typhoon_KGE': results_typhoon[model]['metrics']['KGE'],\n",
    "            'Enhanced_Typhoon_NSE': results_enhanced[model]['metrics']['NSE'],\n",
    "            'Enhanced_Typhoon_RMSE': results_enhanced[model]['metrics']['RMSE'],\n",
    "            'Enhanced_Typhoon_MAE': results_enhanced[model]['metrics']['MAE'],\n",
    "            'Enhanced_Typhoon_KGE': results_enhanced[model]['metrics']['KGE']\n",
    "        }\n",
    "        overall_data.append(row)\n",
    "    \n",
    "    df_overall = pd.DataFrame(overall_data)\n",
    "    df_overall.to_csv('results_v2/comparison_overall.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # Flood period metrics table\n",
    "    flood_data = []\n",
    "    for model in models:\n",
    "        row = {\n",
    "            'Model': model,\n",
    "            'Baseline_NSE_flood': results_baseline[model]['metrics'].get('NSE_flood', np.nan),\n",
    "            'Baseline_RMSE_flood': results_baseline[model]['metrics'].get('RMSE_flood', np.nan),\n",
    "            'Baseline_MAE_flood': results_baseline[model]['metrics'].get('MAE_flood', np.nan),\n",
    "            'Baseline_KGE_flood': results_baseline[model]['metrics'].get('KGE_flood', np.nan),\n",
    "            'Original_Typhoon_NSE_flood': results_typhoon[model]['metrics'].get('NSE_flood', np.nan),\n",
    "            'Original_Typhoon_RMSE_flood': results_typhoon[model]['metrics'].get('RMSE_flood', np.nan),\n",
    "            'Original_Typhoon_MAE_flood': results_typhoon[model]['metrics'].get('MAE_flood', np.nan),\n",
    "            'Original_Typhoon_KGE_flood': results_typhoon[model]['metrics'].get('KGE_flood', np.nan),\n",
    "            'Enhanced_Typhoon_NSE_flood': results_enhanced[model]['metrics'].get('NSE_flood', np.nan),\n",
    "            'Enhanced_Typhoon_RMSE_flood': results_enhanced[model]['metrics'].get('RMSE_flood', np.nan),\n",
    "            'Enhanced_Typhoon_MAE_flood': results_enhanced[model]['metrics'].get('MAE_flood', np.nan),\n",
    "            'Enhanced_Typhoon_KGE_flood': results_enhanced[model]['metrics'].get('KGE_flood', np.nan)\n",
    "        }\n",
    "        flood_data.append(row)\n",
    "    \n",
    "    df_flood = pd.DataFrame(flood_data)\n",
    "    df_flood.to_csv('results_v2/comparison_flood.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"\\nComparison tables saved to:\")\n",
    "    print(\"  - results_v2/comparison_overall.csv (Overall metrics)\")\n",
    "    print(\"  - results_v2/comparison_flood.csv (Flood period metrics)\")\n",
    "\n",
    "# ================== Main Program ==================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main experimental workflow\n",
    "    \"\"\"\n",
    "    print(\"=\"*100)\n",
    "    print(\"Experiment: Impact of Typhoon Features on Runoff and Flood Prediction Accuracy\")\n",
    "    print(\"Compare three scenarios: Baseline, Original Typhoon Features, Enhanced Typhoon Features\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # 1. Prepare data\n",
    "    print(\"\\nStep 1: Preparing data...\")\n",
    "    data_file = '../data/typhoon_daily_boluo.csv'\n",
    "    combined_baseline, combined_typhoon, combined_enhanced = prepare_data(data_file, lag_days=7)\n",
    "    \n",
    "    # 2. Split into training and testing sets\n",
    "    print(\"\\nStep 2: Splitting training and testing sets...\")\n",
    "    train_baseline, test_baseline = split_data(combined_baseline)\n",
    "    train_typhoon, test_typhoon = split_data(combined_typhoon)\n",
    "    train_enhanced, test_enhanced = split_data(combined_enhanced)\n",
    "    \n",
    "    print(f\"Training set size: {len(train_baseline)} samples\")\n",
    "    print(f\"Testing set size: {len(test_baseline)} samples\")\n",
    "    print(f\"Baseline model features: {len(train_baseline.columns) - 2}\")\n",
    "    print(f\"Original typhoon features model features: {len(train_typhoon.columns) - 2}\")\n",
    "    print(f\"Enhanced typhoon features model features: {len(train_enhanced.columns) - 2}\")\n",
    "    \n",
    "    # 3. Identify flood events\n",
    "    print(\"\\nStep 3: Identifying flood events...\")\n",
    "    y_test = test_baseline['boluo_discharge']\n",
    "    dates_test = test_baseline['date']\n",
    "    flood_indices, flood_threshold = identify_flood_events(y_test, dates_test, threshold_percentile=90)\n",
    "    \n",
    "    # 4. Train and evaluate: Baseline model\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"Step 4: Training baseline model (without typhoon features)\")\n",
    "    print(\"=\"*100)\n",
    "    X_train_baseline = train_baseline.drop(['boluo_discharge', 'date'], axis=1)\n",
    "    y_train_baseline = train_baseline['boluo_discharge']\n",
    "    X_test_baseline = test_baseline.drop(['boluo_discharge', 'date'], axis=1)\n",
    "    \n",
    "    results_baseline = train_and_compare(\n",
    "        X_train_baseline, y_train_baseline, \n",
    "        X_test_baseline, y_test, dates_test,\n",
    "        'baseline', flood_indices\n",
    "    )\n",
    "    \n",
    "    # 5. Train and evaluate: Original typhoon features\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"Step 5: Training model with original typhoon features\")\n",
    "    print(\"=\"*100)\n",
    "    X_train_typhoon = train_typhoon.drop(['boluo_discharge', 'date'], axis=1)\n",
    "    y_train_typhoon = train_typhoon['boluo_discharge']\n",
    "    X_test_typhoon = test_typhoon.drop(['boluo_discharge', 'date'], axis=1)\n",
    "    \n",
    "    results_typhoon = train_and_compare(\n",
    "        X_train_typhoon, y_train_typhoon,\n",
    "        X_test_typhoon, y_test, dates_test,\n",
    "        'with_typhoon', flood_indices\n",
    "    )\n",
    "    \n",
    "    # 6. Train and evaluate: Enhanced typhoon features\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"Step 6: Training model with enhanced typhoon features\")\n",
    "    print(\"=\"*100)\n",
    "    X_train_enhanced = train_enhanced.drop(['boluo_discharge', 'date'], axis=1)\n",
    "    y_train_enhanced = train_enhanced['boluo_discharge']\n",
    "    X_test_enhanced = test_enhanced.drop(['boluo_discharge', 'date'], axis=1)\n",
    "    \n",
    "    results_enhanced = train_and_compare(\n",
    "        X_train_enhanced, y_train_enhanced,\n",
    "        X_test_enhanced, y_test, dates_test,\n",
    "        'with_typhoon_enhanced', flood_indices\n",
    "    )\n",
    "    \n",
    "    # 7. Print comparison tables\n",
    "    print_comparison_tables(results_baseline, results_typhoon, results_enhanced)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"Experiment completed!\")\n",
    "    print(\"=\"*100)\n",
    "    print(\"\\nAll results saved to the following directories:\")\n",
    "    print(\"  - models_v2/baseline/: Baseline model files\")\n",
    "    print(\"  - models_v2/with_typhoon/: Original typhoon features model files\")\n",
    "    print(\"  - models_v2/with_typhoon_enhanced/: Enhanced typhoon features model files\")\n",
    "    print(\"  - predictions_v2/: Prediction results CSV files for all models\")\n",
    "    print(\"  - results_v2/: Evaluation metrics JSON files and comparison tables CSV files\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb02db7-d478-4f1e-b8b7-4417e928ea17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
